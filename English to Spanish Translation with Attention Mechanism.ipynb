{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/spa.txt\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import string\nfrom string import digits\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport tensorflow as tf\nimport matplotlib.ticker as ticker\nfrom sklearn.model_selection import train_test_split\nimport re\nimport os\nimport io\nimport time","execution_count":2,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reading the text file of Spanish-English pairs:-"},{"metadata":{"trusted":true},"cell_type":"code","source":"lines=pd.read_table(\"/kaggle/input/spa.txt\",names=['input','target','comments'])\nlines.head(10)","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"  input    target                                           comments\n0   Go.       Ve.  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n1   Go.     Vete.  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n2   Go.     Vaya.  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n3   Go.   Váyase.  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n4   Hi.     Hola.  CC-BY 2.0 (France) Attribution: tatoeba.org #5...\n5  Run!   ¡Corre!  CC-BY 2.0 (France) Attribution: tatoeba.org #9...\n6  Run!  ¡Corran!  CC-BY 2.0 (France) Attribution: tatoeba.org #9...\n7  Run!   ¡Corra!  CC-BY 2.0 (France) Attribution: tatoeba.org #9...\n8  Run!  ¡Corred!  CC-BY 2.0 (France) Attribution: tatoeba.org #9...\n9  Run.   Corred.  CC-BY 2.0 (France) Attribution: tatoeba.org #4...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input</th>\n      <th>target</th>\n      <th>comments</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Go.</td>\n      <td>Ve.</td>\n      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Go.</td>\n      <td>Vete.</td>\n      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Go.</td>\n      <td>Vaya.</td>\n      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Go.</td>\n      <td>Váyase.</td>\n      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Hi.</td>\n      <td>Hola.</td>\n      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Run!</td>\n      <td>¡Corre!</td>\n      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Run!</td>\n      <td>¡Corran!</td>\n      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Run!</td>\n      <td>¡Corra!</td>\n      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Run!</td>\n      <td>¡Corred!</td>\n      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Run.</td>\n      <td>Corred.</td>\n      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"lines=lines[['input','target']]\nlines","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"                                                    input  \\\n0                                                     Go.   \n1                                                     Go.   \n2                                                     Go.   \n3                                                     Go.   \n4                                                     Hi.   \n...                                                   ...   \n124320  There are four main causes of alcohol-related ...   \n124321  There are mothers and fathers who will lie awa...   \n124322  A carbon footprint is the amount of carbon dio...   \n124323  Since there are usually multiple websites on a...   \n124324  If you want to sound like a native speaker, yo...   \n\n                                                   target  \n0                                                     Ve.  \n1                                                   Vete.  \n2                                                   Vaya.  \n3                                                 Váyase.  \n4                                                   Hola.  \n...                                                   ...  \n124320  Hay cuatro causas principales de muertes relac...  \n124321  Hay madres y padres que se quedan despiertos d...  \n124322  Una huella de carbono es la cantidad de contam...  \n124323  Como suele haber varias páginas web sobre cual...  \n124324  Si quieres sonar como un hablante nativo, debe...  \n\n[124325 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Go.</td>\n      <td>Ve.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Go.</td>\n      <td>Vete.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Go.</td>\n      <td>Vaya.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Go.</td>\n      <td>Váyase.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Hi.</td>\n      <td>Hola.</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>124320</th>\n      <td>There are four main causes of alcohol-related ...</td>\n      <td>Hay cuatro causas principales de muertes relac...</td>\n    </tr>\n    <tr>\n      <th>124321</th>\n      <td>There are mothers and fathers who will lie awa...</td>\n      <td>Hay madres y padres que se quedan despiertos d...</td>\n    </tr>\n    <tr>\n      <th>124322</th>\n      <td>A carbon footprint is the amount of carbon dio...</td>\n      <td>Una huella de carbono es la cantidad de contam...</td>\n    </tr>\n    <tr>\n      <th>124323</th>\n      <td>Since there are usually multiple websites on a...</td>\n      <td>Como suele haber varias páginas web sobre cual...</td>\n    </tr>\n    <tr>\n      <th>124324</th>\n      <td>If you want to sound like a native speaker, yo...</td>\n      <td>Si quieres sonar como un hablante nativo, debe...</td>\n    </tr>\n  </tbody>\n</table>\n<p>124325 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# We have separated the English and Spanish Sentences.."},{"metadata":{"trusted":true},"cell_type":"code","source":"lines.sample(5)","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"                                                 input  \\\n49381                       What position do you hold?   \n95846          The trains in Serbia are terribly slow.   \n50341                      He became a nice young man.   \n109643  Why in the world would I want to be a teacher?   \n17575                              I talk in my sleep.   \n\n                                                target  \n49381                          ¿Qué postura sostienes?  \n95846   Los trenes en Serbia van excesivamente lentos.  \n50341           Él se convirtió en un excelente joven.  \n109643      ¿Por qué diablos yo querría ser profesora?  \n17575                           Hablo mientras duermo.  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>49381</th>\n      <td>What position do you hold?</td>\n      <td>¿Qué postura sostienes?</td>\n    </tr>\n    <tr>\n      <th>95846</th>\n      <td>The trains in Serbia are terribly slow.</td>\n      <td>Los trenes en Serbia van excesivamente lentos.</td>\n    </tr>\n    <tr>\n      <th>50341</th>\n      <td>He became a nice young man.</td>\n      <td>Él se convirtió en un excelente joven.</td>\n    </tr>\n    <tr>\n      <th>109643</th>\n      <td>Why in the world would I want to be a teacher?</td>\n      <td>¿Por qué diablos yo querría ser profesora?</td>\n    </tr>\n    <tr>\n      <th>17575</th>\n      <td>I talk in my sleep.</td>\n      <td>Hablo mientras duermo.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"lines=lines.sample(70000)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(lines)","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"70000"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Now preprocessing the statements:-"},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_sentence(sentence):\n    \n    num_digits= str.maketrans('','', digits)\n    \n    sentence= sentence.lower()\n    sentence= re.sub(\" +\", \" \", sentence)\n    sentence= re.sub(\"'\", '', sentence)\n    sentence= sentence.translate(num_digits)\n    sentence= re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)\n    sentence = sentence.rstrip().strip()\n    sentence=  'start_ ' + sentence + ' _end'\n    \n    return sentence","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lines['input']=lines['input'].apply(preprocess_sentence)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lines['input']","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"30735                   start_ the suspect confessed . _end\n56014             start_ is the beam solid or hollow ? _end\n44856                start_ we ought to be back soon . _end\n113311    start_ venice ,  italy is one of the wonders o...\n100949    start_ what do you like most about working her...\n                                ...                        \n118517    start_ tom couldnt find a job in boston ,  so ...\n84562       start_ the problem is youre not canadian . _end\n34034                   start_ ill tell you a secret . _end\n42877                 start_ im going to take a bath . _end\n329                                start_ hi ,  guys . _end\nName: input, Length: 70000, dtype: object"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"lines['target']=lines['target'].apply(preprocess_sentence)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lines['target']","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"30735                   start_ el sospechoso confesó . _end\n56014           start_ ¿ está la viga sólida o hueca ? _end\n44856                start_ deberíamos volver pronto . _end\n113311    start_ venecia en italia es una de las maravil...\n100949    start_ ¿ qué es lo que más te gusta de trabaja...\n                                ...                        \n118517    start_ tom no pudo encontrar trabajo en boston...\n84562     start_ el problema es que tú no eres canadiens...\n34034                   start_ te contaré un secreto . _end\n42877                           start_ voy a bañarme . _end\n329                     start_ ¿ qué pasa ,  troncos ? _end\nName: target, Length: 70000, dtype: object"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(lines)","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"70000"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"rows = lines.to_numpy().tolist()","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rows = np.array(rows)\nrows","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"array([['start_ the suspect confessed . _end',\n        'start_ el sospechoso confesó . _end'],\n       ['start_ is the beam solid or hollow ? _end',\n        'start_ ¿ está la viga sólida o hueca ? _end'],\n       ['start_ we ought to be back soon . _end',\n        'start_ deberíamos volver pronto . _end'],\n       ...,\n       ['start_ ill tell you a secret . _end',\n        'start_ te contaré un secreto . _end'],\n       ['start_ im going to take a bath . _end',\n        'start_ voy a bañarme . _end'],\n       ['start_ hi ,  guys . _end',\n        'start_ ¿ qué pasa ,  troncos ? _end']], dtype='<U279')"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Made English Spanish Pairs.."},{"metadata":{"trusted":true},"cell_type":"code","source":"english=[]\nfor i in lines['input']:\n    english.append(i)","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(english)","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"70000"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"spanish=[]\nfor i in lines['target']:\n    spanish.append(i)","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(spanish)","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"70000"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"english[0]","execution_count":20,"outputs":[{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"'start_ the suspect confessed . _end'"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Creating the input and target tokens:-"},{"metadata":{"trusted":true},"cell_type":"code","source":"input_sentence_tokenizer= tf.keras.preprocessing.text.Tokenizer(filters='')\ninput_sentence_tokenizer.fit_on_texts(english)\ninput_array = input_sentence_tokenizer.texts_to_sequences(english)\ninput_array= tf.keras.preprocessing.sequence.pad_sequences(input_array,padding='post' )","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_array","execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"array([[   1,    4, 2115, ...,    0,    0,    0],\n       [   1,   11,    4, ...,    0,    0,    0],\n       [   1,   31,  990, ...,    0,    0,    0],\n       ...,\n       [   1,   84,   93, ...,    0,    0,    0],\n       [   1,   35,   72, ...,    0,    0,    0],\n       [   1, 2227,   17, ...,    0,    0,    0]], dtype=int32)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_sentence_tokenizer= tf.keras.preprocessing.text.Tokenizer(filters='')\ntarget_sentence_tokenizer.fit_on_texts(spanish)\ntarget_array = target_sentence_tokenizer.texts_to_sequences(english)\ntarget_array= tf.keras.preprocessing.sequence.pad_sequences(target_array,padding='post',maxlen=30)","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_array","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"array([[ 1,  3,  2, ...,  0,  0,  0],\n       [ 1, 10,  2, ...,  0,  0,  0],\n       [ 1,  3,  2, ...,  0,  0,  0],\n       ...,\n       [ 1,  7,  3, ...,  0,  0,  0],\n       [ 1,  7,  3, ...,  0,  0,  0],\n       [ 1, 18,  3, ...,  0,  0,  0]], dtype=int32)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(target_array[0]))","execution_count":25,"outputs":[{"output_type":"stream","text":"30\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_target_length= max(len(t) for t in  target_array)\nprint(max_target_length)\nmax_source_length= max(len(t) for t in  input_array)\nprint(max_source_length)","execution_count":26,"outputs":[{"output_type":"stream","text":"30\n51\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Padding the sentences to a certain length::-"},{"metadata":{"trusted":true},"cell_type":"code","source":"input_sentence_tokenizer= tf.keras.preprocessing.text.Tokenizer(filters='')\ninput_sentence_tokenizer.fit_on_texts(english)\ninput_array = input_sentence_tokenizer.texts_to_sequences(english)\ninput_array= tf.keras.preprocessing.sequence.pad_sequences(input_array,padding='post',maxlen=20)","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_sentence_tokenizer= tf.keras.preprocessing.text.Tokenizer(filters='')\ntarget_sentence_tokenizer.fit_on_texts(spanish)\ntarget_array = target_sentence_tokenizer.texts_to_sequences(spanish)\ntarget_array= tf.keras.preprocessing.sequence.pad_sequences(target_array,padding='post',maxlen=30)","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_sentence_tokenizer","execution_count":29,"outputs":[{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"<keras_preprocessing.text.Tokenizer at 0x7fed21ebda50>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_sentence_tokenizer","execution_count":30,"outputs":[{"output_type":"execute_result","execution_count":30,"data":{"text/plain":"<keras_preprocessing.text.Tokenizer at 0x7fed21cc10d0>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Train Test Split:-"},{"metadata":{"trusted":true},"cell_type":"code","source":"input_train, input_val, target_train, target_val = train_test_split(input_array, target_array, test_size=0.2)\n\nprint(len(input_train), len(target_train), len(input_val), len(target_val))","execution_count":31,"outputs":[{"output_type":"stream","text":"56000 56000 14000 14000\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# 80-20 Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(input_sentence_tokenizer.word_index)+1)","execution_count":32,"outputs":[{"output_type":"stream","text":"11128\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(target_sentence_tokenizer.word_index)+1)","execution_count":33,"outputs":[{"output_type":"stream","text":"20980\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"When the dataset is big, we want to create the dataset in memory to be efficient. We will use tf.data.Dataset.from_tensor_slices() method to get slices of the array in the form of an object."},{"metadata":{"trusted":true},"cell_type":"code","source":"buffer_size = len(input_train)\nbatch_size = 64\nsteps_per_epoch = len(input_train)//batch_size\nembedding_dim = 256\nunits = 1024\nvocab_input_size = len(input_sentence_tokenizer.word_index)+1\nvocab_target_size = len(target_sentence_tokenizer.word_index)+1\n\ndataset = tf.data.Dataset.from_tensor_slices((input_train, target_train)).shuffle(buffer_size)\ndataset = dataset.batch(batch_size, drop_remainder=True)\n# print(type(dataset))","execution_count":34,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Encoder-Decoder Architecture:-"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Encoder(tf.keras.Model):\n    def __init__(self,vocab_size,embedding_size,units,batchsize):\n        super(Encoder, self).__init__()\n        self.batchsize=batchsize\n        self.units=units\n        self.embedding=tf.keras.layers.Embedding(vocab_size, embedding_dim)\n        self.gru=tf.keras.layers.GRU(self.units,return_sequences=True,return_state=True,recurrent_initializer='glorot_uniform')# entire sequence of outputs will be returned from all the units.\n        #To return the internal state of GRU, we set the return_state to True\n        # this returns 3 parameters in LSTM with return states and sequences true but in GRU it returns only 2 parameters..\n    \n    def call(self,y,hidden):\n        y=self.embedding(y)\n        output,state=self.gru(y,initial_state=hidden)\n        return output,state\n\n    def initialize_hidden_state(self):\n        return tf.zeros((self.batchsize, self.units))","execution_count":36,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"example_input_batch, example_target_batch = next(iter(dataset))\nexample_input_batch.shape, example_target_batch.shape","execution_count":37,"outputs":[{"output_type":"execute_result","execution_count":37,"data":{"text/plain":"(TensorShape([64, 20]), TensorShape([64, 30]))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder = Encoder(vocab_input_size, embedding_dim, units,batch_size )\n\nsample_hidden = encoder.initialize_hidden_state()\nsample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\nprint ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\nprint ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))","execution_count":38,"outputs":[{"output_type":"stream","text":"Encoder output shape: (batch size, sequence length, units) (64, 20, 1024)\nEncoder Hidden state shape: (batch size, units) (64, 1024)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Creating a Bahdanau Attention Layer:-"},{"metadata":{},"cell_type":"markdown","source":"Attention layer consists:-\n\nAlignment Score\n\nAttention weights\n\nContext vector"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Attention(tf.keras.layers.Layer):\n    def __init__(self, units):\n        super(Attention,self).__init__()\n        self.W1 = tf.keras.layers.Dense(units)\n        self.W2 = tf.keras.layers.Dense(units)\n        self.V = tf.keras.layers.Dense(1)\n    \n    # The encoder hiiden states are taken as input to the attention layer which are of shape (batch size, units)\n    # and the encoder output of each timestep is of shape (batch size, sequence length, units).\n    # so for adding we have to expand dimensions\n    def call(self,encoder_out,encoder_hid):\n        \n       hidden1=tf.expand_dims(encoder_hid,1)\n        \n        \n       # score shape == (batch_size, max_length, 1)\n       # we get 1 at the last axis because we are applying score to self.V\n       # the shape of the array before applying self.V is (batch_size, max_length, units)\n       score = self.V(tf.nn.tanh(\n          self.W1(encoder_out) + self.W2(hidden1)))\n\n       # attention_weights shape == (batch_size, max_length, 1)\n       attention_weights = tf.nn.softmax(score, axis=1) ## the alignment scores for each encoder hidden state\n        #are combined and represented in a single vector and subsequently softmaxed\n\n       # context_vector shape after sum == (batch_size, hidden_size)\n       context_vector = attention_weights * encoder_out ## attention weights multiplied with the encoder output states are used to calculate the context vactor\n        \n       context_vector = tf.reduce_sum(context_vector, axis=1)\n\n       return context_vector, attention_weights ## returning the context vector and the attention_weights","execution_count":39,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"attention_layer = Attention(10)# 10 for units of attention\nattention_result, attention_weights = attention_layer(sample_output,sample_hidden)\n\nprint(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\nprint(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))","execution_count":40,"outputs":[{"output_type":"stream","text":"Attention result shape: (batch size, units) (64, 1024)\nAttention weights shape: (batch_size, sequence_length, 1) (64, 20, 1)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# The context vector should be of the shape of (batch size, units) as it be combined with the decoder previous embeddings.."},{"metadata":{},"cell_type":"markdown","source":"# Decoder Class:-"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Decoder(tf.keras.Model):\n    def __init__(self,vocab_size,embedding_size,units,batchsize):\n        super(Decoder, self).__init__()\n        self.batchsize=batchsize\n        self.units=units\n        self.embedding=tf.keras.layers.Embedding(vocab_size, embedding_dim)\n        self.gru=tf.keras.layers.GRU(self.units,return_sequences=True,return_state=True,recurrent_initializer='glorot_uniform')# entire sequence of outputs will be returned from all the units.\n        #To return the internal state of GRU, we set the return_state to True\n        \n        #fully connected layer for the decoder outputs\n        self.fc = tf.keras.layers.Dense(vocab_size)\n        \n        # attention layer\n        self.attention=Attention(self.units)\n        \n    def call(self, x, enc_output,hidden):\n        # enc_output shape == (batch_size, max_length, hidden_size)\n        context_vector, attention_weights = self.attention(enc_output,hidden)\n#         print(context_vector.shape)\n\n        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n        x = self.embedding(x)\n#         print(x.shape)\n        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)## context vaector is added with the previous decoder hidden state.\n       \n        # passing the concatenated vector to the GRU\n        output, state = self.gru(x)\n\n        # output shape == (batch_size * 1, hidden_size)\n        output = tf.reshape(output, (-1, output.shape[2]))\n\n        # output shape == (batch_size, vocab)\n        x = self.fc(output)\n\n        return x, state, attention_weights       ","execution_count":41,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decoder = Decoder(vocab_target_size, embedding_dim, units, batch_size)\n\nsample_decoder_output, _, _ = decoder(tf.random.uniform((batch_size, 1)),\n                                      sample_output, sample_hidden)\n\nprint ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))","execution_count":42,"outputs":[{"output_type":"stream","text":"Decoder output shape: (batch_size, vocab size) (64, 20980)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Defining the Optimiser and Loss Function:-"},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = tf.keras.optimizers.Adam()\nloss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n    from_logits=True, reduction='none')\n\ndef loss_function(real, pred):\n  mask = tf.math.logical_not(tf.math.equal(real, 0))\n  loss_ = loss_object(real, pred)\n\n  mask = tf.cast(mask, dtype=loss_.dtype)\n  loss_ *= mask\n\n  return tf.reduce_mean(loss_)","execution_count":43,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_sentence_tokenizer.word_index['start_']","execution_count":45,"outputs":[{"output_type":"execute_result","execution_count":45,"data":{"text/plain":"1"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_step(inp, target, encoder_hidden):\n  loss = 0\n\n  with tf.GradientTape() as tape:\n    encoder_output, encoder_hidden = encoder(inp, enc_hidden)\n\n    decoder_hidden = encoder_hidden\n\n    decoder_input = tf.expand_dims([target_sentence_tokenizer.word_index['start_']] * batch_size, 1)\n\n    # Teacher forcing \n    for t in range(1, target.shape[1]):\n      # passing enc_output to the decoder\n      predictions, decoder_hidden, _ = decoder(decoder_input, encoder_output, decoder_hidden)\n\n      loss += loss_function(target[:, t], predictions)\n\n      # using teacher forcing\n      dec_input = tf.expand_dims(target[:, t], 1)\n\n  batch_loss = (loss / int(target.shape[1]))\n\n  variables = encoder.trainable_variables + decoder.trainable_variables\n\n  gradients = tape.gradient(loss, variables)\n\n  optimizer.apply_gradients(zip(gradients, variables))\n\n  return batch_loss","execution_count":46,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"steps_per_epoch","execution_count":47,"outputs":[{"output_type":"execute_result","execution_count":47,"data":{"text/plain":"875"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 5\n\nfor epoch in range(epochs):\n  start = time.time()\n\n  enc_hidden = encoder.initialize_hidden_state()\n  total_loss = 0\n\n  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n    batch_loss = train_step(inp, targ, enc_hidden)\n    total_loss += batch_loss\n    if batch % 100 == 0:\n      print('EPOCH:- {} BATCH:- {} LOSS:- {}'.format(epoch + 1,batch, batch_loss.numpy()))\n   \n\n  print('EPOCH:- {} Loss:- {:.5f}'.format(epoch + 1,\n                                      total_loss / steps_per_epoch))\n  print('Time taken for this Epoch {} sec\\n'.format(time.time() - start))","execution_count":48,"outputs":[{"output_type":"stream","text":"EPOCH:- 1 BATCH:- 0 LOSS:- 2.6692914962768555\nEPOCH:- 1 BATCH:- 100 LOSS:- 1.554011583328247\nEPOCH:- 1 BATCH:- 200 LOSS:- 1.5967878103256226\nEPOCH:- 1 BATCH:- 300 LOSS:- 1.7050445079803467\nEPOCH:- 1 BATCH:- 400 LOSS:- 1.5926105976104736\nEPOCH:- 1 BATCH:- 500 LOSS:- 1.5504059791564941\nEPOCH:- 1 BATCH:- 600 LOSS:- 1.6022757291793823\nEPOCH:- 1 BATCH:- 700 LOSS:- 1.656678557395935\nEPOCH:- 1 BATCH:- 800 LOSS:- 1.3925235271453857\nEPOCH:- 1 Loss:- 1.57393\nTime taken for this Epoch 466.7751874923706 sec\n\nEPOCH:- 2 BATCH:- 0 LOSS:- 1.414547324180603\nEPOCH:- 2 BATCH:- 100 LOSS:- 1.3436685800552368\nEPOCH:- 2 BATCH:- 200 LOSS:- 1.378778338432312\nEPOCH:- 2 BATCH:- 300 LOSS:- 1.3461782932281494\nEPOCH:- 2 BATCH:- 400 LOSS:- 1.3486477136611938\nEPOCH:- 2 BATCH:- 500 LOSS:- 1.2581250667572021\nEPOCH:- 2 BATCH:- 600 LOSS:- 1.426490068435669\nEPOCH:- 2 BATCH:- 700 LOSS:- 1.2014590501785278\nEPOCH:- 2 BATCH:- 800 LOSS:- 1.3172775506973267\nEPOCH:- 2 Loss:- 1.31184\nTime taken for this Epoch 464.2180075645447 sec\n\nEPOCH:- 3 BATCH:- 0 LOSS:- 1.2088454961776733\nEPOCH:- 3 BATCH:- 100 LOSS:- 1.1700340509414673\nEPOCH:- 3 BATCH:- 200 LOSS:- 1.1149362325668335\nEPOCH:- 3 BATCH:- 300 LOSS:- 1.1964666843414307\nEPOCH:- 3 BATCH:- 400 LOSS:- 1.1171270608901978\nEPOCH:- 3 BATCH:- 500 LOSS:- 1.1519947052001953\nEPOCH:- 3 BATCH:- 600 LOSS:- 1.0099966526031494\nEPOCH:- 3 BATCH:- 700 LOSS:- 1.122705101966858\nEPOCH:- 3 BATCH:- 800 LOSS:- 1.0638222694396973\nEPOCH:- 3 Loss:- 1.09997\nTime taken for this Epoch 461.39597392082214 sec\n\nEPOCH:- 4 BATCH:- 0 LOSS:- 0.9654774069786072\nEPOCH:- 4 BATCH:- 100 LOSS:- 1.0649954080581665\nEPOCH:- 4 BATCH:- 200 LOSS:- 0.9339174032211304\nEPOCH:- 4 BATCH:- 300 LOSS:- 0.9892944097518921\nEPOCH:- 4 BATCH:- 400 LOSS:- 0.8083403706550598\nEPOCH:- 4 BATCH:- 500 LOSS:- 0.889366090297699\nEPOCH:- 4 BATCH:- 600 LOSS:- 0.9105899930000305\nEPOCH:- 4 BATCH:- 700 LOSS:- 1.0936789512634277\nEPOCH:- 4 BATCH:- 800 LOSS:- 1.1036115884780884\nEPOCH:- 4 Loss:- 0.94269\nTime taken for this Epoch 459.4465956687927 sec\n\nEPOCH:- 5 BATCH:- 0 LOSS:- 0.7743297219276428\nEPOCH:- 5 BATCH:- 100 LOSS:- 0.8325257897377014\nEPOCH:- 5 BATCH:- 200 LOSS:- 0.8480527997016907\nEPOCH:- 5 BATCH:- 300 LOSS:- 0.9006614089012146\nEPOCH:- 5 BATCH:- 400 LOSS:- 0.9128695726394653\nEPOCH:- 5 BATCH:- 500 LOSS:- 0.8036433458328247\nEPOCH:- 5 BATCH:- 600 LOSS:- 0.913811445236206\nEPOCH:- 5 BATCH:- 700 LOSS:- 0.8646337389945984\nEPOCH:- 5 BATCH:- 800 LOSS:- 0.8032195568084717\nEPOCH:- 5 Loss:- 0.81922\nTime taken for this Epoch 457.63557147979736 sec\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(sentence):\n  attention_plot = np.zeros((max_target_length, max_source_length))\n\n  sentence = preprocess_sentence(sentence)\n\n  inputs = [input_sentence_tokenizer.word_index[i] for i in sentence.split(' ')]\n  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n                                                         maxlen=max_source_length,\n                                                         padding='post')\n  inputs = tf.convert_to_tensor(inputs)\n\n  result = ''\n\n  hidden = [tf.zeros((1, units))]\n  enc_out, enc_hidden = encoder(inputs, hidden)\n\n  dec_hidden = enc_hidden\n  dec_input = tf.expand_dims([target_sentence_tokenizer.word_index['start_']], 0)\n\n  for t in range(max_target_length):\n    predictions, dec_hidden, attention_weights = decoder(dec_input,\n                                                         enc_out,\n                                                         dec_hidden\n                                                         )\n\n    attention_weights = tf.reshape(attention_weights, (-1, ))\n\n\n    predicted_id = tf.argmax(predictions[0]).numpy()\n\n    result += target_sentence_tokenizer.index_word[predicted_id] + ' '\n\n    if target_sentence_tokenizer.index_word[predicted_id] == '_end':\n      return result, sentence\n\n    dec_input = tf.expand_dims([predicted_id], 0)\n\n  return result, sentence","execution_count":49,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def translate(sentence):\n  result, sentence = evaluate(sentence)\n  \n  print('Input: %s' % (sentence))\n  print('Predicted translation: {}'.format(result))","execution_count":51,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"translate('Hello.')","execution_count":56,"outputs":[{"output_type":"stream","text":"Input: start_ hello . _end\nPredicted translation: hola . _end \n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"translate('Hello everyone.')","execution_count":53,"outputs":[{"output_type":"stream","text":"Input: start_ hello everyone . _end\nPredicted translation: hola todos . _end \n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"translate('How are you?')","execution_count":54,"outputs":[{"output_type":"stream","text":"Input: start_ how are you ? _end\nPredicted translation: ¿ cómo estás _end \n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"translate('I am working from home.')","execution_count":55,"outputs":[{"output_type":"stream","text":"Input: start_ i am working from home . _end\nPredicted translation: estoy trabajando . _end \n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"translate('Learning Spanish.')","execution_count":62,"outputs":[{"output_type":"stream","text":"Input: start_ learning spanish . _end\nPredicted translation: aprender un _end \n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"translate('Lets Hope for the best.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Trained with 5 epochs as saw with 10 epochs the model was overfitted.."},{"metadata":{},"cell_type":"markdown","source":"# For more accurate results we have to train it with more samples and accordingly more epochs.."}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}